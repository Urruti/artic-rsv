//
// Notes to End Users.
//
// The workflow should run without editing this configuration file,
// however there may be instances in which you wish to edit this
// file for compute performance or other reasons. Please see:
//
//   https://nextflow.io/docs/latest/config.html#configuration
//
// for further help editing this file.

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')

params {
    // Boilerplate options
    out_dir                     = "output"
    //tracedir                   = "${params.out_dir}/pipeline_info/${trace_timestamp}"
    publish_dir_mode           = 'copy'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    hook_url                   = null
    help                       = false
    version                    = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = false

    refs = "${projectDir}/resources/RSV_refs.fasta"
    bed = "${projectDir}/resources/primer_bed_files/*"
    schemes_dir = "${projectDir}/resources/"
    fastq = null
    min = 400
    max = 2500
    medaka_model = "r1041_e82_400bps_hac_v4.2.0"

    wf {
          example_cmd = [
              "--fastq test_data/barcode01/reads.fastq.gz",
          ]
          agent = null
          container = "dmmalone/artic_rsv:0.0.3"
          container_sha = "sha256:7d82de61af27b67792c9d376d302a89e5c286c475d92b0da82c531dbb7157f1e"
        }
}


manifest {
    name            = 'artic-network/artic-rsv'
    author          = 'Daniel Maloney'
    homePage        = 'https://github.com/artic-network/artic-rsv/'
    description     = 'Generate assemblies from RSV sequence data generated using the ARTIC primer scheme.'
    mainScript      = 'main.nf'
    nextflowVersion = '>=20.10.0'
    version         = 'v0.0.1'
}

profiles {
    standard {
        docker {
            enabled = true
        }
    }
    debug {
        dumpHashes             = true
        process.beforeScript   = 'echo $HOSTNAME'
        cleanup = false
    }
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    docker {
        docker.enabled         = true
        docker.registry        = 'docker.io'
        docker.userEmulation   = true
        conda.enabled          = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        conda.enabled          = false
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    podman {
        podman.enabled         = true
        podman.registry        = 'quay.io'
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    shifter {
        shifter.enabled        = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    charliecloud {
        charliecloud.enabled   = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        apptainer.enabled      = false
    }
    apptainer {
        apptainer.enabled      = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 16
        executor.memory        = 60.GB
    }
    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }
}


// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
    enabled = true
    overwrite = true
    file    = "${params.out_dir}/execution/timeline.html"
}
report {
    enabled = true
    overwrite = true
    file    = "${params.out_dir}/execution/report.html"
}
trace {
    enabled = true
    overwrite = true
    file    = "${params.out_dir}/execution/trace.txt"
}
dag {
    enabled = true
    overwrite = true
    file    = "${params.out_dir}/execution/pipeline_dag.html"
}


// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
